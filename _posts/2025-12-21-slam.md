---
layout: post
title: "SLAM"
date: 2025-12-21
tags: vision c++
---

## Core Concepts of SLAM
* Map is needed for localization
* Pose estimation is needed to build a map
* Sensor Noise & drift
* Ambiguous observations
* Dynamic environment
* Real-time constraints

## Sensor Fusion
* Lidar (2D, 3D)
* Camera (RGB, Depth) (Mono, Stereo)
* IMU
* Wheel encoder
* Sonar (Ultrasonic)
* Radar

## Structure from Motion
* Feature Extraction
* Feature Matching
* Camera Poses
* Triangulation
* Incremental Reconstruction
* Bundle Adjustment
* [Theia - algorithms for Structure from Motion (SfM)](http://theia-sfm.org/)
* [Bundle Adjustment in the Large](https://grail.cs.washington.edu/projects/bal/)
* [COLMAP](https://colmap.github.io/)
* [openMVG](https://github.com/openMVG/openMVG)
* [VisualSFM : A Visual Structure from Motion System](http://ccwu.me/vsfm/)
* [FLOT: Scene Flow on Point Clouds guided by Optimal Transport](https://github.com/valeoai/FLOT)
* [ByteTrack](https://blog.roboflow.com/what-is-bytetrack-computer-vision/)

## Popular SLAM frameworks
* [DROID-SLAM](https://github.com/princeton-vl/DROID-SLAM)
* [SLAM Toolbox](https://github.com/SteveMacenski/slam_toolbox)
* [RTAB-Map](https://introlab.github.io/rtabmap/)
* [MOLA (Modular Optimization frameworkfor Localization and Mapping)](https://docs.mola-slam.org/latest/)
* [LeGO-LOAM](https://github.com/RobustFieldAutonomyLab/LeGO-LOAM)
* [LIO-SAM](https://github.com/TixiaoShan/LIO-SAM)
* [Fast-LIO2](https://github.com/hku-mars/FAST_LIO)
* [OpenVINS](https://docs.openvins.com/)
* [ORB-SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3)

## AI/ML and SLAM
* Monocular Depth Prediction - [MiDaS](https://github.com/isl-org/MiDaS) , [Depth Anything](https://github.com/DepthAnything/Depth-Anything-V2)
* Learned Place Recognition
* Motion Segmentation via ML
* Learned Feature Extraction & Matching
* Semantic Segmentation & Object Detection

## CNN and Visual Models

### Classification
* [AlexNet - 2012](https://viso.ai/deep-learning/alexnet/)
* [VGG - 2014](https://viso.ai/deep-learning/vgg-very-deep-convolutional-networks/)
* [GoogLeNet - 2014](https://viso.ai/deep-learning/googlenet-explained-the-inception-model-that-won-imagenet/)
* [ResNet - 2015](https://huggingface.co/microsoft/resnet-50)

### Object Detection
* [R-CNN - 2014](https://blog.roboflow.com/what-is-r-cnn/)
* [YoLo - You Only Look Once - 2015](https://www.datacamp.com/blog/yolo-object-detection-explained)
* [SSD - single-shot detector - 2016](https://developers.arcgis.com/python/latest/guide/how-ssd-works/)

### Segmentation
* [FCN - Fully Convolutional Networks - 2015](https://github.com/shelhamer/fcn.berkeleyvision.org)
* [U-net - 2015](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)
* [Mask R-CNN - 2017](https://www.ultralytics.com/blog/what-is-mask-r-cnn-and-how-does-it-work)

### Efficientcy Era
* [MobileNet - 2017](https://huggingface.co/docs/transformers/model_doc/mobilenet_v1)
* [ShuffleNet - 2017](https://github.com/jaxony/ShuffleNet)
* [EfficientNet - 2019](https://blog.roboflow.com/what-is-efficientnet/)

### Attention and Vision Transformers
* [ViT - 2020](https://huggingface.co/docs/transformers/model_doc/vit)
* [DeiT - 2021](https://huggingface.co/docs/transformers/model_doc/deit)
* [ConvNeXT - 2022](https://huggingface.co/docs/transformers/model_doc/convnext)

### Foundation and Generative Vision Models
* [CLIP - 2021](https://openai.com/index/clip/)
* [DINO - 2021](https://huggingface.co/docs/transformers/model_doc/dinov2)
* [Stable Diffusion - 2022](https://stable-diffusion-art.com/models/)
* [SAM - 2023](https://huggingface.co/docs/transformers/model_doc/sam2)
* [SORA - 2024](https://openai.com/index/sora/)

## Datasets
* [ImageNet](https://image-net.org/)
* [MS COCO](https://cocodataset.org/#home)
* [Open Images](https://storage.googleapis.com/openimages/web/index.html)
* [Kinetics](https://www.kaggle.com/datasets/ipythonx/k4testset)

## References
* [Vladimir Georgiev - AI за компютърно зрение и роботика](https://www.youtube.com/watch?v=yd7SPDIDiwM)
* <https://github.com/VladiGGeorgiev>
* [Can Modern C++ SPEED UP Your Bundle Adjustment Pipeline? - Vishnu Sudheer Menon](https://www.youtube.com/watch?v=Bnl35DhfnUs)
* [SLAM for Mobile Robotics: Localization and Mapping in the Real World](https://dev.bg/event/slam-for-mobile-robotics-localization-and-mapping-in-the-real-world/)
* <https://github.com/ali-pahlevani>
* [Large Scale Interactive Motion Forecasting for Autonomous Driving : The WAYMO OPEN MOTION DATASET](https://openaccess.thecvf.com/content/ICCV2021/papers/Ettinger_Large_Scale_Interactive_Motion_Forecasting_for_Autonomous_Driving_The_Waymo_ICCV_2021_paper.pdf)
* [Multi-Agent Trajectory Prediction with Scalable Diffusion Transformer](https://dl.acm.org/doi/10.1145/3719545.3720337)
* [Vincent Sitzmann - Machine Learning for Inverse Graphics](https://ocw.mit.edu/courses/6-s980-machine-learning-for-inverse-graphics-fall-2022/)
* [Rafael C. Gonzalez, Richard E. Woods - Digital Image Processing](https://www.cl72.org/090imagePLib/books/Gonzales,Woods-Digital.Image.Processing.4th.Edition.pdf)
* [Richard Szeliski - Computer Vision: Algorithms and Applications](https://library.huree.edu.mn/data/202295/2024-06-03/Computer%20Vision%20-%20Algorithms%20and%20Applications%202nd%20Edition,%20Richard%20Szeliski.pdf)
